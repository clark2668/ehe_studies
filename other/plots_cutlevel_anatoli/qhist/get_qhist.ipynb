{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from copy import copy\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import helper\n",
    "traj = helper.build_anatoli_trajcetory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neutrino_level.steps.general_modules.read_data import load_dfs\n",
    "mc_df, data_df = load_dfs(\n",
    "    traj, ignore_tables=helper.to_ignore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stochasticity_observable_ import get_1d_rlogl\n",
    "from stochasticity_observable_ import spline, Likelihood_1D\n",
    "\n",
    "sys.path.append('/Users/brianclark/Documents/work/IceCube/ehe/ehe_deps/energy_loss_pdfs')\n",
    "from likelihood import Likelihood_1D\n",
    "\n",
    "get_1d_rlogl(\n",
    "    mc_df,\n",
    "    Likelihood_1D(spline),\n",
    "    table_name='EHEMuMillipede_SplineMPEseed_vecd',\n",
    "    key_name='stochasticity',\n",
    "    min_bins=8,\n",
    "    n_bins_to_combine=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stoch_thresh = 8.374043045935741\n",
    "rlogl_mask = mc_df['stochasticity'] >= stoch_thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def track_quality_cut(speed=None, npe=None,\n",
    "                      charge_scale=1.):\n",
    "    '''\n",
    "    Input: np.ndarrays of values to base the cut on\n",
    "    Returns: mask, where \"True\" indicates an event *PASSES* the cut\n",
    "    '''\n",
    "    # pass charge cut\n",
    "    mask1 = npe > (10**4.65 * charge_scale)\n",
    "    \n",
    "    # does *NOT* pass the track speed cut below 0.26 (cascade like)\n",
    "    low_speed = speed <= 0.26\n",
    "    low_mask = np.logical_and(low_speed, npe < (10**5.25 * charge_scale))\n",
    "    \n",
    "    # does *NOT* pass the track speed cut between 0.26 and 0.28\n",
    "    intermediate_speed = np.logical_and(speed > 0.26,\n",
    "                                    speed < 0.28)\n",
    "    intermediate_charge_thresh = (\n",
    "        np.power(10, 5.25 - (0.6/0.02) * (speed - 0.26)))\n",
    "    intermediate_mask = np.logical_and(\n",
    "        intermediate_speed,\n",
    "        npe < (intermediate_charge_thresh * charge_scale))\n",
    "      \n",
    "    # total mask (mask1 and NOT low mask and NOT intermediate mask)\n",
    "    total_mask = np.logical_and(\n",
    "        mask1, ~intermediate_mask\n",
    "    )\n",
    "    total_mask = np.logical_and(\n",
    "       total_mask, ~low_mask \n",
    "    )\n",
    "    return total_mask\n",
    "\n",
    "\n",
    "def muon_bundle_cut_stoch_opt(\n",
    "        mc_df,\n",
    "        reco_zen_key='EHEOpheliaParticleSRT_ImpLF.zenith',\n",
    "        npe_key='EHEPortiaEventSummary.atwdNPEbtw',\n",
    "        inplace=False,\n",
    "        charge_scale=1.,\n",
    "        floor=4.55,\n",
    "        ceil=6.05,\n",
    "        denom=0.9,\n",
    "        inflection_point=0.1,\n",
    "        pwr=2.5):\n",
    "    # Apply base cut\n",
    "    mask = mc_df[npe_key] >= (10**floor * charge_scale)\n",
    "    \n",
    "    # Add zenith dependent npe cut\n",
    "    above_horizon = np.cos(mc_df[reco_zen_key]) >= inflection_point\n",
    "    npe_thresh = np.power(10, floor + (ceil-floor) *\n",
    "                          np.sqrt(1 - np.power((1-np.cos(mc_df[reco_zen_key]))/denom, pwr)))\n",
    "    npe_mask = np.logical_and(\n",
    "        above_horizon,\n",
    "        mc_df[npe_key] < (npe_thresh * charge_scale))\n",
    "    mask = np.logical_and(mask, ~npe_mask)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_low = {\n",
    "    'floor': 4.7,\n",
    "    'inflection_point': 0.1,\n",
    "    'ceil': 6.25,\n",
    "    'denom': 0.9,\n",
    "    'pwr': 1.5\n",
    "}\n",
    "\n",
    "params_high = {\n",
    "    'floor': 4.65,\n",
    "    'inflection_point': 0.1,\n",
    "    'ceil': 5.7,\n",
    "    'denom': 0.9,\n",
    "    'pwr': 4\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "charge_scale = 1.27 * 0.94\n",
    "\n",
    "bundle_mask_low = np.logical_and(\n",
    "    muon_bundle_cut_stoch_opt(\n",
    "        mc_df,\n",
    "        reco_zen_key='EHE_SplineMPE.zenith',\n",
    "        npe_key='Homogenized_QTot.value',\n",
    "        charge_scale=charge_scale,\n",
    "        **params_low\n",
    "    ),\n",
    "    ~rlogl_mask\n",
    ")\n",
    "\n",
    "bundle_mask_high = np.logical_and(\n",
    "    muon_bundle_cut_stoch_opt(\n",
    "        mc_df,\n",
    "        reco_zen_key='EHE_SplineMPE.zenith',\n",
    "        npe_key='Homogenized_QTot.value',\n",
    "        charge_scale=charge_scale,\n",
    "        **params_high\n",
    "    ),\n",
    "    rlogl_mask\n",
    ")\n",
    "\n",
    "bundle_mask = np.logical_or(\n",
    "    bundle_mask_low,\n",
    "    bundle_mask_high\n",
    ")\n",
    "\n",
    "track_quality_mask = track_quality_cut(\n",
    "    mc_df['EHELineFit.speed'],\n",
    "    mc_df['Homogenized_QTot.value'],\n",
    "    charge_scale=charge_scale\n",
    ")\n",
    "\n",
    "pass_L3 = track_quality_mask\n",
    "\n",
    "selection_mask = np.logical_and(\n",
    "    bundle_mask,\n",
    "    track_quality_mask\n",
    ")\n",
    "\n",
    "pass_L4 = selection_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the juliet weights\n",
    "\n",
    "from neutrino_level.steps.general_modules.label_maker import type_to_label\n",
    "\n",
    "def get_idx_from_comp(df, comp):\n",
    "    idx = np.array(df['Label'] == type_to_label[comp], dtype=bool)\n",
    "    return idx\n",
    "\n",
    "juliet_weights_L2 = np.asarray([])\n",
    "juliet_charge_L2 = np.asarray([])\n",
    "\n",
    "juliet_weights_L3 = np.asarray([])\n",
    "juliet_charge_L3 = np.asarray([])\n",
    "\n",
    "juliet_weights_L4 = np.asarray([])\n",
    "juliet_charge_L4 = np.asarray([])\n",
    "\n",
    "charge_var = 'Homogenized_QTot.value'\n",
    "weighting_strat = 'Weights.ahlers_2010_1E18'\n",
    "\n",
    "components = ['nue_cc', 'numu_cc', 'nutau_cc', 'neutrino_nc', 'nue_gr']\n",
    "for comp in components:\n",
    "    \n",
    "    mc_pass_L2 = mc_df\n",
    "    mc_pass_L3 = mc_df.loc[pass_L3]\n",
    "    mc_pass_L4 = mc_df.loc[pass_L4]\n",
    "    \n",
    "    # L2\n",
    "    comp_idx = get_idx_from_comp(mc_pass_L2, comp)\n",
    "    juliet_values_pass_L2 = mc_pass_L2.loc[comp_idx, charge_var]\n",
    "    juliet_weights_pass_L2 = mc_pass_L2.loc[comp_idx, weighting_strat] * np.pi * 1E7 # per year\n",
    "    juliet_weights_L2 = np.concatenate((juliet_weights_L2, juliet_weights_pass_L2))\n",
    "    juliet_charge_L2 = np.concatenate((juliet_charge_L2, juliet_values_pass_L2))\n",
    "    \n",
    "    # L3\n",
    "    comp_idx = get_idx_from_comp(mc_pass_L3, comp)\n",
    "    juliet_values_pass_L3 = mc_pass_L3.loc[comp_idx, charge_var]\n",
    "    juliet_weights_pass_L3 = mc_pass_L3.loc[comp_idx, weighting_strat] * np.pi * 1E7 # per year\n",
    "    juliet_weights_L3 = np.concatenate((juliet_weights_L3, juliet_weights_pass_L3))\n",
    "    juliet_charge_L3 = np.concatenate((juliet_charge_L3, juliet_values_pass_L3))\n",
    "\n",
    "    # L4\n",
    "    comp_idx = get_idx_from_comp(mc_pass_L4, comp)\n",
    "    juliet_values_pass_L4 = mc_pass_L4.loc[comp_idx, charge_var]\n",
    "    juliet_weights_pass_L4 = mc_pass_L4.loc[comp_idx, weighting_strat] * np.pi * 1E7 # per year\n",
    "    juliet_weights_L4 = np.concatenate((juliet_weights_L4, juliet_weights_pass_L4))\n",
    "    juliet_charge_L4 = np.concatenate((juliet_charge_L4, juliet_values_pass_L4))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the corsika weights\n",
    "\n",
    "charge_var = 'Homogenized_QTot.value'\n",
    "corsika_weighting_strat = 'Weights.GaisserH3a'\n",
    "idx = np.array(mc_df['Label'] == 6, dtype=bool)\n",
    "\n",
    "corsika_weights_L2 = np.asarray([])\n",
    "corsika_charge_L2 = np.asarray([])\n",
    "\n",
    "corsika_weights_L3 = np.asarray([])\n",
    "corsika_charge_L3 = np.asarray([])\n",
    "\n",
    "corsika_weights_L4 = np.asarray([])\n",
    "corsika_charge_L4 = np.asarray([])\n",
    "\n",
    "mc_pass_L2 = mc_df\n",
    "mc_pass_L3 = mc_df.loc[pass_L3]\n",
    "mc_pass_L4 = mc_df.loc[pass_L4]\n",
    "    \n",
    "# L2\n",
    "comp_ix = np.array(mc_pass_L2['Label'] == 6, dtype=bool)\n",
    "corsika_values_pass_L2 = mc_pass_L2.loc[comp_ix, charge_var]\n",
    "corsika_weights_pass_L2 = mc_pass_L2.loc[comp_ix, corsika_weighting_strat] * np.pi * 1E7 # per year\n",
    "corsika_weights_L2 = np.concatenate((corsika_weights_L2, corsika_weights_pass_L2))\n",
    "corsika_charge_L2 = np.concatenate((corsika_charge_L2, corsika_values_pass_L2))\n",
    "\n",
    "# L3\n",
    "comp_ix = np.array(mc_pass_L3['Label'] == 6, dtype=bool)\n",
    "corsika_values_pass_L3 = mc_pass_L3.loc[comp_ix, charge_var]\n",
    "corsika_weights_pass_L3 = mc_pass_L3.loc[comp_ix, corsika_weighting_strat] * np.pi * 1E7 # per year\n",
    "corsika_weights_L3 = np.concatenate((corsika_weights_L3, corsika_weights_pass_L3))\n",
    "corsika_charge_L3 = np.concatenate((corsika_charge_L3, corsika_values_pass_L3))\n",
    "\n",
    "# L4\n",
    "comp_ix = np.array(mc_pass_L4['Label'] == 6, dtype=bool)\n",
    "corsika_values_pass_L4 = mc_pass_L4.loc[comp_ix, charge_var]\n",
    "corsika_weights_pass_L4 = mc_pass_L4.loc[comp_ix, corsika_weighting_strat] * np.pi * 1E7 # per year\n",
    "corsika_weights_L4 = np.concatenate((corsika_weights_L4, corsika_weights_pass_L4))\n",
    "corsika_charge_L4 = np.concatenate((corsika_charge_L4, corsika_values_pass_L4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.logspace(2,8,100)\n",
    "\n",
    "fig = plt.figure(figsize=(8.5,3.5))\n",
    "ax_juliet = fig.add_subplot(1,2,1)\n",
    "ax_corsika = fig.add_subplot(1,2,2)\n",
    "\n",
    "ax_juliet.hist(\n",
    "    juliet_charge_L2, weights= juliet_weights_L2,\n",
    "    bins=bins, label='Passes L1', histtype='step', lw=2\n",
    ")\n",
    "ax_juliet.hist(\n",
    "    juliet_charge_L3, weights= juliet_weights_L3,\n",
    "    bins=bins, label='Passes L2+L3', histtype='step', lw=2\n",
    ")\n",
    "ax_juliet.hist(\n",
    "    juliet_charge_L4, weights= juliet_weights_L4,\n",
    "    bins=bins, label='Passes L4', histtype='step', lw=2\n",
    ")\n",
    "\n",
    "ax_corsika.hist(\n",
    "    corsika_charge_L2, weights= corsika_weights_L2,\n",
    "    bins=bins, label='Passes L1', histtype='step', lw=2\n",
    ")\n",
    "ax_corsika.hist(\n",
    "    corsika_charge_L3, weights= corsika_weights_L3,\n",
    "    bins=bins, label='Passes L2+L3', histtype='step', lw=2\n",
    ")\n",
    "ax_corsika.hist(\n",
    "    corsika_charge_L4, weights= corsika_weights_L4,\n",
    "    bins=bins, label='Passes L4', histtype='step', lw=2\n",
    ")\n",
    "\n",
    "for ax in [ax_juliet, ax_corsika]:\n",
    "    ax.set_xscale('log')\n",
    "    ax.set_yscale('log')\n",
    "    ax.set_xlabel('HQtot [PE]')\n",
    "\n",
    "ax_juliet.set_ylabel('Events per Year')\n",
    "ax_juliet.legend()\n",
    "ax_juliet.set_ylim([1E-3, 3E-2])\n",
    "ax_juliet.set_ylim([1E-6, 1E6])\n",
    "ax_juliet.set_xlim([10**3.6, 1E8])\n",
    "ax_juliet.set_title(r'GZK $\\nu$ (Ahlers 2010 E18)')\n",
    "\n",
    "ax_corsika.set_ylabel('Events per Year')\n",
    "ax_corsika.set_ylim([1E-6, 1E6])\n",
    "ax_corsika.set_xlim([10**3.6, 1E8])\n",
    "ax_corsika.set_title(r'Atm $\\mu$ (H3a)')\n",
    "# ax.corsika.set_ylabel('')\n",
    "    \n",
    "plt.tight_layout()\n",
    "# plt.subplots_adjust(wspace=0.45)\n",
    "fig.savefig('cut_levels.png', dpi=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.sum(corsika_weights_L4)*12)\n",
    "print(np.sum(juliet_weights_L4)*12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ehe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
