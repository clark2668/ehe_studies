{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neutrino_level.steps.general_modules.read_data import load_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from copy import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import helper\n",
    "traj = helper.build_trajectory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_df, data_df = load_dfs(\n",
    "    traj, ignore_tables=helper.to_ignore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stochasticity_observable_ import get_1d_rlogl\n",
    "from stochasticity_observable_ import spline, Likelihood_1D\n",
    "\n",
    "sys.path.append('/Users/brianclark/Documents/work/IceCube/ehe/ehe_deps/energy_loss_pdfs')\n",
    "from likelihood import Likelihood_1D\n",
    "\n",
    "get_1d_rlogl(\n",
    "    mc_df,\n",
    "    Likelihood_1D(spline),\n",
    "    table_name='EHEMuMillipede_SplineMPEseed_vecd',\n",
    "    key_name='stochasticity',\n",
    "    min_bins=8,\n",
    "    n_bins_to_combine=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stoch_thresh = 8.374043045935741\n",
    "rlogl_mask = mc_df['stochasticity'] >= stoch_thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def track_quality_cut(speed=None, npe=None):\n",
    "    '''\n",
    "    Input: np.ndarrays of values to base the cut on\n",
    "    Returns: mask, where \"True\" indicates an event *PASSES* the cut\n",
    "    '''\n",
    "    # pass charge cut\n",
    "    mask1 = npe > 10**4.65\n",
    "    \n",
    "    # does *NOT* pass the track speed cut below 0.26 (cascade like)\n",
    "    low_speed = speed <= 0.26\n",
    "    low_mask = np.logical_and(low_speed, npe < 10**5.25)\n",
    "    \n",
    "    # does *NOT* pass the track speed cut between 0.26 and 0.28\n",
    "    intermediate_speed = np.logical_and(speed > 0.26,\n",
    "                                    speed < 0.28)\n",
    "    intermediate_charge_thresh = (\n",
    "        np.power(10, 5.25 - (0.6/0.02) * (speed - 0.26)))\n",
    "    intermediate_mask = np.logical_and(\n",
    "        intermediate_speed,\n",
    "        npe < intermediate_charge_thresh)\n",
    "      \n",
    "    # total mask (mask1 and NOT low mask and NOT intermediate mask)\n",
    "    total_mask = np.logical_and(\n",
    "        mask1, ~intermediate_mask\n",
    "    )\n",
    "    total_mask = np.logical_and(\n",
    "       total_mask, ~low_mask \n",
    "    )\n",
    "    return total_mask\n",
    "\n",
    "\n",
    "def muon_bundle_cut_stoch_opt(\n",
    "        mc_df,\n",
    "        reco_zen_key='EHEOpheliaParticleSRT_ImpLF.zenith',\n",
    "        npe_key='EHEPortiaEventSummary.atwdNPEbtw',\n",
    "        inplace=False,\n",
    "        floor=4.55,\n",
    "        ceil=6.05,\n",
    "        denom=0.9,\n",
    "        inflection_point=0.1,\n",
    "        pwr=2.5):\n",
    "    # Apply base cut\n",
    "    mask = mc_df[npe_key] >= 10**floor\n",
    "    \n",
    "    # Add zenith dependent npe cut\n",
    "    above_horizon = np.cos(mc_df[reco_zen_key]) >= inflection_point\n",
    "    npe_thresh = np.power(10, floor + (ceil-floor) *\n",
    "                          np.sqrt(1 - np.power((1-np.cos(mc_df[reco_zen_key]))/denom, pwr)))\n",
    "    npe_mask = np.logical_and(\n",
    "        above_horizon,\n",
    "        mc_df[npe_key] < npe_thresh)\n",
    "    mask = np.logical_and(mask, ~npe_mask)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_low = {\n",
    "    'floor': 4.7,\n",
    "    'inflection_point': 0.1,\n",
    "    'ceil': 6.25,\n",
    "    'denom': 0.9,\n",
    "    'pwr': 1.5\n",
    "}\n",
    "\n",
    "params_high = {\n",
    "    'floor': 4.65,\n",
    "    'inflection_point': 0.1,\n",
    "    'ceil': 5.7,\n",
    "    'denom': 0.9,\n",
    "    'pwr': 4\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bundle_mask_low = np.logical_and(\n",
    "    muon_bundle_cut_stoch_opt(\n",
    "        mc_df,\n",
    "        reco_zen_key='EHE_SplineMPE.zenith',\n",
    "        npe_key='Homogenized_QTot.value',\n",
    "        **params_low\n",
    "    ),\n",
    "    ~rlogl_mask\n",
    ")\n",
    "\n",
    "bundle_mask_high = np.logical_and(\n",
    "    muon_bundle_cut_stoch_opt(\n",
    "        mc_df,\n",
    "        reco_zen_key='EHE_SplineMPE.zenith',\n",
    "        npe_key='Homogenized_QTot.value',\n",
    "        **params_high\n",
    "    ),\n",
    "    rlogl_mask\n",
    ")\n",
    "\n",
    "bundle_mask = np.logical_or(\n",
    "    bundle_mask_low,\n",
    "    bundle_mask_high\n",
    ")\n",
    "\n",
    "track_quality_mask = track_quality_cut(\n",
    "    mc_df['EHELineFit.speed'],\n",
    "    mc_df['Homogenized_QTot.value']\n",
    ")\n",
    "\n",
    "selection_mask = np.logical_and(\n",
    "    bundle_mask,\n",
    "    track_quality_mask\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_old = {\n",
    "    'floor': 4.6,\n",
    "    'inflection_point': 0.06,\n",
    "    'ceil': 6.45,\n",
    "    'denom': 0.94,\n",
    "    'pwr': 2.\n",
    "}\n",
    "\n",
    "## Test if just doing the low stoch cut will approximately reproduce old effective areas\n",
    "bundle_mask_check = muon_bundle_cut_stoch_opt(\n",
    "    mc_df,\n",
    "    reco_zen_key='EHE_SplineMPE.zenith',\n",
    "    npe_key='Homogenized_QTot.value',\n",
    "    **params_old\n",
    ")\n",
    "\n",
    "selection_mask_check = np.logical_and(\n",
    "    bundle_mask_check,\n",
    "    track_quality_mask\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_mc_df = mc_df.loc[selection_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neutrino_level.steps.general_modules.juliet_weighting import calc_juliet_effective_area\n",
    "from neutrino_level.steps.general_modules.juliet_weighting import get_juliet_weightdict_and_propmatrix\n",
    "import tables\n",
    "e_bins = np.logspace(5, 12, 141)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_events_per_file(juliet_species, juliet_energy_level):\n",
    "    n_he = 150\n",
    "    n_vhe = 20\n",
    "    nu_scaling = 4\n",
    "    \n",
    "    evts_per_file = -1\n",
    "    \n",
    "    if juliet_species in ['nue', 'numu', 'nutau']:\n",
    "        if juliet_energy_level == 'vhe':\n",
    "            evts_per_file = n_vhe * nu_scaling\n",
    "        else:\n",
    "            evts_per_file = n_he * nu_scaling\n",
    "    else:\n",
    "        if juliet_energy_level == 'vhe':\n",
    "            if juliet_species == 'tau':\n",
    "                evts_per_file = 100\n",
    "            else:\n",
    "                evts_per_file = n_vhe\n",
    "        else:\n",
    "            evts_per_file = n_he\n",
    "    \n",
    "    return evts_per_file\n",
    "\n",
    "\n",
    "\n",
    "run_ids = mc_df.index.get_level_values(0)\n",
    "\n",
    "eff_area_dict = {}\n",
    "eff_area_dict_check = {}\n",
    "\n",
    "for comp in traj.parameters.components:\n",
    "    print(comp._name)\n",
    "    species, energy_level = comp._name.split('_')\n",
    "    for file_i, n_files_i in zip(comp.file_list, comp.n_files_loaded):\n",
    "        with tables.open_file(file_i) as open_file:\n",
    "            weight_dict, prop_matrix, evts_per_file = \\\n",
    "                get_juliet_weightdict_and_propmatrix(open_file)\n",
    "            evts_per_file = correct_events_per_file(species, energy_level)\n",
    "            primary_energy = open_file.get_node(\n",
    "                '/MCPrimary').col('energy')\n",
    "            log_energy_max = np.log10(np.max(primary_energy))\n",
    "            \n",
    "            if comp.type.endswith('nue'):\n",
    "                pdg_id = 12\n",
    "            elif comp.type.endswith('numu'):\n",
    "                pdg_id = 14\n",
    "            elif comp.type.endswith('nutau'):\n",
    "                pdg_id = 16\n",
    "            elif comp.type.endswith('mu'):\n",
    "                pdg_id = 13\n",
    "            elif comp.type.endswith('tau'):\n",
    "                pdg_id = 15\n",
    "\n",
    "            ds_id_base = pdg_id * 100000\n",
    "            if log_energy_max > 9.0:\n",
    "                ds_id_base += 10000\n",
    "                \n",
    "            run_id_mask = np.logical_and(\n",
    "                run_ids >= ds_id_base,\n",
    "                run_ids < ds_id_base + 10000\n",
    "            )\n",
    "\n",
    "            mask = selection_mask[run_id_mask]\n",
    "            mask_ = selection_mask_check[run_id_mask]\n",
    "            \n",
    "            for prop_matrix_flavor, flavor in zip(\n",
    "                    prop_matrix, ['nue', 'numu', 'nutau']):\n",
    "\n",
    "                eff_area = calc_juliet_effective_area(\n",
    "                    energies=primary_energy,\n",
    "                    weight_dict=weight_dict,\n",
    "                    n_gen=evts_per_file*n_files_i,\n",
    "                    energy_bins=e_bins,\n",
    "                    prop_matrix=prop_matrix_flavor,\n",
    "                    selection_mask=mask\n",
    "                )\n",
    "                eff_area_dict[comp._name + f'_{flavor}'] = eff_area.sum(axis=0)\n",
    "                \n",
    "                eff_area_check = calc_juliet_effective_area(\n",
    "                    energies=primary_energy,\n",
    "                    weight_dict=weight_dict,\n",
    "                    n_gen=evts_per_file*n_files_i,\n",
    "                    energy_bins=e_bins,\n",
    "                    prop_matrix=prop_matrix_flavor,\n",
    "                    selection_mask=mask_\n",
    "                )\n",
    "                eff_area_dict_check[comp._name + f'_{flavor}'] = eff_area_check.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "areas_from_nue = [eff_area_dict[key] for key in eff_area_dict.keys() if key.endswith('nue')]\n",
    "areas_from_numu = [eff_area_dict[key] for key in eff_area_dict.keys() if key.endswith('numu')]\n",
    "areas_from_nutau = [eff_area_dict[key] for key in eff_area_dict.keys() if key.endswith('nutau')]\n",
    "\n",
    "areas_from_nue_check = [eff_area_dict_check[key] for key in eff_area_dict_check.keys() if key.endswith('nue')]\n",
    "areas_from_numu_check = [eff_area_dict_check[key] for key in eff_area_dict_check.keys() if key.endswith('numu')]\n",
    "areas_from_nutau_check = [eff_area_dict_check[key] for key in eff_area_dict_check.keys() if key.endswith('nutau')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_center = (e_bins[1:] + e_bins[:-1]) / 2\n",
    "bin_width = np.diff(e_bins)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "for i, (areas, label_i) in enumerate(zip([areas_from_nue, areas_from_numu, areas_from_nutau],\n",
    "                                        ['NuE', 'NuMu', 'NuTau'])):\n",
    "    ax.plot(bin_center, np.sum(areas, axis=0), drawstyle='steps-mid',\n",
    "            color=f'C{i}')\n",
    "    ax.errorbar(bin_center, np.sum(areas, axis=0),\n",
    "                xerr=bin_width/2.,\n",
    "                label=f'{label_i}',\n",
    "                fmt='.', markersize=0,\n",
    "                color=f'C{i}')\n",
    "for i, (areas, label_i) in enumerate(zip([areas_from_nue_check, areas_from_numu_check, areas_from_nutau_check],\n",
    "                                        ['NuE', 'NuMu', 'NuTau'])):\n",
    "    ax.plot(bin_center, np.sum(areas, axis=0), drawstyle='steps-mid',\n",
    "            color=f'C{i}', ls='--')\n",
    "    ax.errorbar(bin_center, np.sum(areas, axis=0),\n",
    "                xerr=bin_width/2.,\n",
    "                label=f'{label_i}',\n",
    "                fmt='.', markersize=0,\n",
    "                color=f'C{i}', ls='--')\n",
    "ax.legend()\n",
    "ax.set_xscale('log')\n",
    "ax.set_yscale('log')\n",
    "ax.set_xlim(5e5, 1e11)\n",
    "ax.set_ylim(1e0, 5e4)\n",
    "ax.set_xlabel(r'$E_{\\nu}$ / GeV')\n",
    "ax.set_ylabel(r'$A_{\\mathrm{eff}} \\,\\, / \\,\\, \\mathrm{m}^2$')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_aeff = np.sum(areas_from_nue, axis=0) + np.sum(areas_from_numu, axis=0) + np.sum(areas_from_nutau, axis=0)\n",
    "\n",
    "# average the effective areas together to get total sensitivity to the neutrino flux\n",
    "total_aeff = total_aeff/3. # make flavor average\n",
    "\n",
    "# smooth out the effective area a bit\n",
    "bin_center = bin_center[5:-4] # drop 10 bins\n",
    "total_aeff = np.convolve(total_aeff, np.ones(10)/10, mode='valid') # average\n",
    "total_aeff = total_aeff * CM2_TO_M2 # convert to m2\n",
    "total_aeff_sr = total_aeff * 4 * np.pi # convert to m2 str (mult by 4pi)\n",
    "\n",
    "np.savez('ehenextgen_total_aeff.npz',\n",
    "         bin_center=bin_center,\n",
    "         avg_aeff_m2sr=total_aeff_sr\n",
    "         )\n",
    "\n",
    "from old_analysis_results import diff_limit_9yr, diff_limit_7yr, LIVETIME_9YR\n",
    "from old_analysis_results import CM2_TO_M2\n",
    "LIVETIME_12YR = 12 * 365 * 24 * 3600\n",
    "from ehefluxes import fluxes\n",
    "\n",
    "flux_spl = fluxes.EHEFlux('ahlers_gzk')\n",
    "flux_spl_2010 = fluxes.EHEFlux('cosmogenic_ahlers2010_1E18')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_e2_differential_limit(energies, total_aeff_sr, livetime):\n",
    "        # input \n",
    "        # energies (in real units, eV)\n",
    "        # flavor averaged effective area (in m2)\n",
    "        # livetime (in seconds)\n",
    "        \n",
    "        # returns\n",
    "        # E^2 * F(E) (GeV/cm2/s/sr)\n",
    "        n_90 = 2.44\n",
    "        return n_90 * energies / (livetime * np.log(10) * total_aeff_sr)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(bin_center,\n",
    "        simple_e2_differential_limit(bin_center,\n",
    "                                  total_aeff_sr,\n",
    "                                  LIVETIME_9YR),\n",
    "        label='New EHE 8.15yrs IC86 equiv, sensitivity')\n",
    "ax.plot(bin_center,\n",
    "        simple_e2_differential_limit(bin_center,\n",
    "                                  total_aeff_sr,\n",
    "                                  LIVETIME_12YR),\n",
    "        label='New EHE 12yrs, sensitivity')\n",
    "ax.plot(diff_limit_9yr[:, 0], diff_limit_9yr[:, 1], label='EHE 9yrs', color='k')\n",
    "ax.plot(diff_limit_7yr[:, 0], diff_limit_7yr[:, 1], label='EHE 7yrs', color='k', ls='--')\n",
    "\n",
    "energies = np.logspace(5, 12, 141)\n",
    "\n",
    "ax.plot(energies, energies**2 * flux_spl(energies, 'sum'), label='Ahlers 2012')\n",
    "ax.plot(energies, energies**2 * flux_spl_2010(energies, 'sum'), label='Ahlers 2010 1 EeV')\n",
    "\n",
    "ax.set_xscale('log')\n",
    "ax.set_yscale('log')\n",
    "ax.set_xlabel('E / GeV')\n",
    "ax.legend(bbox_to_anchor=(1.,0.85,0.,0))\n",
    "ax.set_ylim(1e-10, 1e-6)\n",
    "ax.set_xlim(1e6, 1e11)\n",
    "ax.set_ylabel(r'E$^2 \\cdot \\Phi$ / (GeV cm$^{-2}$ sr$^{-1}$ s$^{-1}$)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(bin_center,\n",
    "        simple_e2_differential_limit(bin_center,\n",
    "                                  total_aeff_sr,\n",
    "                                  LIVETIME_12YR),\n",
    "        label='EHE UL 12yrs, sensitivity (this work)')\n",
    "ax.plot(diff_limit_9yr[:, 0], diff_limit_9yr[:, 1], label='EHE UL 9yrs', color='k')\n",
    "ax.plot(diff_limit_7yr[:, 0], diff_limit_7yr[:, 1], label='EHE UL 7yrs', color='k', ls='--')\n",
    "\n",
    "energies = np.logspace(5, 12, 141)\n",
    "\n",
    "ax.plot(energies, energies**2 * flux_spl_2010(energies, 'sum'), label='Ahlers 2010 1 EeV', color='grey')\n",
    "ax.plot(energies, energies**2 * flux_spl(energies, 'sum'), label='Ahlers 2012', color='grey', ls='--')\n",
    "\n",
    "ax.set_xscale('log')\n",
    "ax.set_yscale('log')\n",
    "ax.set_xlabel('E / GeV')\n",
    "ax.legend(bbox_to_anchor=(1.,0.85,0.,0))\n",
    "ax.set_ylim(1e-10, 5e-7)\n",
    "ax.set_xlim(5e6, 1e11)\n",
    "ax.set_ylabel(r'E$^2 \\cdot \\Phi$ / (GeV cm$^{-2}$ sr$^{-1}$ s$^{-1}$)')\n",
    "ax.text(6e6, 3e-7, 'IceCube Work-in-progress', color='red')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ehe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
